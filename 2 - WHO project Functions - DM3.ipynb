{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### This notebook contains the FULL function for both models. please run all cells before using and ensure that .csv data is a common local file directory\n"],"metadata":{"id":"hPzRB4zx0FMv"}},{"cell_type":"markdown","source":["#### Import functions from standard libaries"],"metadata":{"id":"JDexNDtzzpLC"}},{"cell_type":"code","source":["# Import libraries\n","import sys #import System-specific functions\n","import numpy as np  # Numerical computing library\n","import seaborn as sns  # Data visualisation library based on Matplotlib\n","import matplotlib.pyplot as plt  # Plotting library\n","import pandas as pd  # Data analysis and manipulation library\n","\n","# Import machine learning tools from scikit-learn\n","from sklearn.model_selection import train_test_split  # Splits data into training and testing sets\n","from sklearn.preprocessing import RobustScaler  # Scales features using robust statistics to handle outliers\n","from sklearn.preprocessing import StandardScaler  # Scales features to have zero mean and unit variance\n","# Import statistical modeling tools from statsmodels\n","import statsmodels.api as sm  # Provides classes for estimating different statistical models\n","import statsmodels.tools  # Utility functions for statistical modeling\n","from statsmodels.stats.outliers_influence import variance_inflation_factor #import VIF"],"metadata":{"id":"X2o1UB_mMKl8","executionInfo":{"status":"ok","timestamp":1744051500772,"user_tz":-60,"elapsed":14546,"user":{"displayName":"dylan Lewis","userId":"15607918061727945647"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["#### Full function"],"metadata":{"id":"ZzocE9w8ugOC"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"tFRe7aVvMFXC","executionInfo":{"status":"ok","timestamp":1744051486223,"user_tz":-60,"elapsed":78,"user":{"displayName":"dylan Lewis","userId":"15607918061727945647"}}},"outputs":[],"source":["def main():    #main function, setup train test split, gain user input, predict final value\n","\n","    global X_train_fe, X_train, base_df, Country_df, feature_columns, safe_columns, model_number\n","\n","    #read in dataframe from csv file\n","    base_df = pd.read_csv('Life Expectancy Data.csv')\n","\n","    #generate country dataframe\n","    Country_df= base_df[['Country','Region']]\n","    Country_df['Country'] = Country_df['Country'].str.lower()\n","\n","    #columns to be used in safe and unsafe models\n","    feature_columns= ['Region', 'Under_five_deaths',\n","       'Adult_mortality' ,'BMI',  'Incidents_HIV',\n","       'GDP_per_capita', 'Schooling']\n","\n","    safe_columns= ['BMI','GDP_per_capita',\n","        'Adult_mortality','Schooling']\n","\n","    X = base_df[feature_columns]\n","    y= base_df['Life_expectancy']\n","\n","    #train test split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","    #selects the safe or unsafe model\n","    model_number = select_model()\n","    if model_number == '0':\n","        #feature engineer training data\n","        X_train_fe = unsafe_feature_engineering(X_train)\n","    elif model_number == '1':\n","        #feature engineer training data\n","        X_train_fe = safe_feature_engineering(X_train)\n","    else:\n","        #raise error when incorrect value entered\n","        raise Exception(\"Incorrect value entered\")\n","\n","    lin_reg = sm.OLS(y_train, X_train_fe)\n","\n","    # Fit the LinReg model\n","    output = lin_reg.fit()\n","\n","    output.summary()\n","    User_input =predict_values()\n","\n","    # Using the model to predict on the training set\n","    y_pred = output.predict(User_input)\n","    #print prediction\n","    print('predicted life expectancy: ',y_pred.iloc[0])\n","\n","\n","def select_model():     #this function asks the user which model they want to use\n","\n","    # 'while' loop entered so question is repeated until a valid input is recieved or input is exited\n","    while True:\n","        model = input(\"Type 0 to consent to use of sensitive data or type 1 to revoke consent :\\n(or type 'exit' to quit):\").strip()\n","    # Allow user exit\n","        if model.lower() in ('exit', ''):\n","            print(\"Exiting model selection...\")\n","            return None\n","    # Catches all integer inputs\n","        try:\n","            if model == \"0\":\n","                print(\"Unsafe model selected\")\n","                return model\n","                break\n","            elif model == \"1\":\n","                print(\"Safe model selected\")\n","                return model\n","                break\n","            else:\n","                print(\"Please enter a valid input\")\n","        #invalid inputs are caught and user is re-prompted\n","        except ValueError:\n","            print(\"Please enter a valid input\")\n","\n","def predict_values():                   #function used to gain user inputs, and pass values to be feature engineered\n","\n","    Country_df.index.drop\n","\n","    #select unsafe model\n","    if model_number == '0':\n","\n","        #find metrics using the unsafe columns\n","        metrics = ask_for_metrics(feature_columns)\n","        #run prediction\n","        input_prediction = run_unsafe_model(metrics)\n","\n","    #select safe model\n","    elif model_number =='1':\n","\n","        #find metrics using the safe columns\n","        metrics = ask_for_metrics(safe_columns)\n","\n","        #run prediction\n","        input_prediction = run_safe_model(metrics)\n","    else:\n","        #raise error when incorrect value entered\n","        raise Exception(\"Incorrect value entered\")\n","\n","    return input_prediction\n","\n","\n","def ask_for_metrics(columns_list):          #asks the user to input their metrics\n","\n","    #make output dictonary\n","    column_values = {'const': 1.0}\n","\n","    #itterate through all values in feature columns asking for inputs\n","    for col in columns_list:\n","\n","        #When region is needed ask user for country then find appropriate region\n","        if col == 'Region':\n","            #find_region_from_input(columns_list)\n","            #fetch user input and pass to lower\n","            User_Country = input(f'Please input you country ').lower().strip()\n","            #find region that matches inputter country\n","            value = Country_df[(Country_df['Country']== User_Country)]['Region'].iloc[0]\n","            #add region to prediction dictonary\n","            column_values[col] = value\n","\n","        #When asking if Economy is developed this is binary (either developed or developing)\n","        elif col == 'Economy_status_Developed': #this need an if exists check\n","            #ask user for input\n","            User_developed = input(f'Please enter 1 for developed, 0 for developing ')\n","\n","            #1 = developed country\n","            if User_developed == '1':\n","                if 'Economy_status_Developed' in columns_list:\n","                    column_values['Economy_status_Developed'] = User_developed\n","                if 'Economy_status_Develoing' in columns_list:\n","                    column_values['Economy_status_Developing'] = '0'\n","\n","            #0 = developing country\n","            elif User_developed == '0':\n","                if 'Economy_status_Developed' in columns_list:\n","                    column_values['Economy_status_Developed'] = '0'\n","                if 'Economy_status_Develoing' in columns_list:\n","                    column_values['Economy_status_Developing'] = User_developed\n","\n","        elif col == 'Economy_status_Developing':\n","            #return output as dictonary\n","            return column_values\n","\n","        else:\n","\n","            #min and max values are gained to give a suggested range\n","            max_value = base_df[col].max()\n","            min_value = base_df[col].min()\n","            #itterate through remaining feilds for user input\n","            #ask user for input\n","            if col == 'Adult_mortality'or  col == 'Under_five_deaths' or col =='Incidents_HIV':\n","                value = input(f\"Please input your {col}. Values are expected to be scaled per 1,000 \").strip()\n","            elif col == 'BMI':\n","                value = input(f\"Please input your {col}. Values expected between: 0 and 40 \").strip()\n","            elif col == 'Schooling':\n","                value = input(f\"Please input your {col}. Values expected between: 0 and 15 \").strip()\n","            else:\n","                value = input(f\"Please input your {col}. Values expected between: 0 and {max_value} \").strip()\n","\n","            # Allow early exit\n","            if value.lower() in ('exit', ''):\n","                sys.exit(\"Exiting feature input...\")\n","\n","            #users will be warned when the input value is unexpectedly large or small\n","            try:\n","                if float(value) > (max_value*1.5):\n","                    print(f'****WARNING VALUE INPUT FOR FEILD {col} IS LARGER THAN EXPECTED****')\n","                elif float(value) < (min_value*0.1):\n","                    print(f'****WARNING VALUE INPUT FOR FEILD {col} IS SMALLER THAN EXPECTED****')\n","                value = float(value)\n","                column_values[col] = value\n","            except ValueError:\n","                raise Exception(f'value Inputted in {col} was not numeric. Error: Please enter a numeric value or type \"exit\" to quit. ')\n","\n","    #return output as dictonary\n","    return column_values\n","\n","\n","def unsafe_feature_engineering(df): #handles the unsafe feature engineering for the training data\n","    global unsafe_scaler\n","    df = df.copy()\n","\n","    df = df[['Under_five_deaths', 'Adult_mortality', 'Schooling', 'BMI', 'GDP_per_capita', 'Incidents_HIV','Region']]\n","    df = pd.get_dummies(df, columns = ['Region'], drop_first = True, prefix = 'region', dtype=int)\n","    # Standardize features\n","    unsafe_scaler = StandardScaler()\n","    df_scaled = pd.DataFrame(unsafe_scaler.fit_transform(df), columns=df.columns, index=df.index)\n","\n","    # Add constant for regression\n","    df_scaled = sm.add_constant(df_scaled)\n","\n","    return df_scaled\n","\n","def safe_feature_engineering(df):    #handles the safe feature engineering for the training data\n","    global safe_scaler\n","    df = df.copy()\n","    df = df[['Adult_mortality', 'Schooling', 'BMI', 'GDP_per_capita']]\n","    # Standardize features\n","    safe_scaler = StandardScaler()\n","    df['gdp_log'] = np.log(df['GDP_per_capita'])\n","    df_scaled = pd.DataFrame(safe_scaler.fit_transform(df), columns=df.columns, index=df.index)\n","    # Add constant for regression\n","    df_scaled = sm.add_constant(df_scaled)\n","\n","    return df_scaled\n","\n","def safe_feature_engineering_input(df): #handles the safe feature engineering for the user input\n","\n","    df = df.copy()\n","    df = df[['Adult_mortality', 'Schooling', 'BMI', 'GDP_per_capita']]\n","    # Standardize features\n","    df['gdp_log'] = np.log(df['GDP_per_capita'])\n","    df_scaled = pd.DataFrame(safe_scaler.transform(df), columns=df.columns, index=df.index)\n","    # Add constant for regression\n","    df_scaled['const'] = 1\n","\n","    return df_scaled\n","\n","def unsafe_feature_engineering_input(df): #handles the unsafe feature engineering for the user input\n","    df = df.copy()\n","    df = df[['Under_five_deaths', 'Adult_mortality', 'Schooling', 'BMI', 'GDP_per_capita', 'Incidents_HIV','Region']]\n","    df = find_region_from_input(df)\n","    # Standardize features\n","    df_scaled = pd.DataFrame(unsafe_scaler.transform(df), columns=df.columns, index=df.index)\n","    # Add constant for regression\n","    df_scaled['const'] = 1\n","\n","    return df_scaled\n","\n","def run_safe_model(column_values):      #function will take in 'safe' user values and feature engineer them\n","    #makes a new dataframe object that will be used in for prediction\n","    column_values = pd.DataFrame(column_values, index=[0])\n","    #feature engineer user inputted dataframe\n","    column_values = safe_feature_engineering_input(column_values)\n","    #re-index user dataframe so that columns are aligned with training the set\n","    column_values = column_values.reindex(columns=X_train_fe.columns)\n","    return column_values\n","\n","def run_unsafe_model(column_values):          #function will take in 'safe' user values and feature engineer them\n","\n","    #makes a new dataframe object that will be used in for prediction\n","    column_values = pd.DataFrame(column_values, index=[0])\n","    #feature engineer user inputted dataframe\n","    column_values =unsafe_feature_engineering_input(column_values)\n","    #re-index user dataframe so that columns are aligned with training the set\n","    column_values = column_values.reindex(columns=X_train_fe.columns)\n","\n","    return column_values\n","\n","def find_region_from_input(column_values):  #this will complete the OHE for the inputted user region\n","\n","    #get all one-hot encoded columns\n","    region_columns = [col for col in X_train_fe.columns if 'region_' in col]\n","    #extract region from inputted dataframe\n","    user_region = column_values['Region'].iloc[0]\n","\n","    #create a new DataFrame with all region columns\n","    region_encoding = {col: 0 for col in region_columns}\n","\n","    #find the correct OHE column for the user's region and set it to 1\n","    region_col_name = f'region_{user_region}'\n","    region_encoding[region_col_name] = 1\n","\n","    #remove the original 'Region' column and update with one-hot encoding\n","    column_values.drop(columns=['Region'], inplace=True)\n","    column_values = column_values.assign(**region_encoding)\n","\n","    return column_values\n","\n"]},{"cell_type":"markdown","source":["#### Run the main function"],"metadata":{"id":"ifwhbmsZz1WG"}},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"nddMR42tzuFh","executionInfo":{"status":"error","timestamp":1744051507864,"user_tz":-60,"elapsed":668,"user":{"displayName":"dylan Lewis","userId":"15607918061727945647"}},"outputId":"b7704674-90b9-4fdf-ce69-a9d270e79392"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Life Expectancy Data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-2d0e1056f525>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#read in dataframe from csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbase_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Life Expectancy Data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#generate country dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Life Expectancy Data.csv'"]}]}]}